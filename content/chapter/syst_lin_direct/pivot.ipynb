{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    Notebook de cours MAP412 - Chapitre 4 - M. Massot 2020-2021 - Ecole polytechnique\n",
    "#    ----------   \n",
    "#    Analyse sur la stabilité des algorithmes de résolution directe de système linéaires\n",
    "#         Choix du pivotage ou non, pivot partiel ou total.\n",
    "#    \n",
    "#    Auteurs : L. Séries et M. Massot - (C) 2021\n",
    "#    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix du pivot         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from mpmath import mp\n",
    "\n",
    "from scipy.stats import ortho_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def gaussian_elimination_without_pivoting(a, b): \n",
    "    n = b.size\n",
    "    for i in range(n-1):\n",
    "        # elimination\n",
    "        li = a[i+1:,i]/a[i,i]\n",
    "        b[i+1:] = b[i+1:] - li * b[i]\n",
    "        a[i+1:] = a[i+1:] - li.reshape(n-i-1,1)*a[i]\n",
    "\n",
    "def gaussian_elimination_with_partial_pivoting(a, b): \n",
    "    n = b.size\n",
    "    for i in range(n-1):\n",
    "        # partial pivoting    \n",
    "        i_max = np.argmax(np.abs(a[i:,i]))\n",
    "        a[[i,i_max+i]] = a[[i_max+i,i]]\n",
    "        b[[i,i_max+i]] = b[[i_max+i,i]]\n",
    "        # elimination\n",
    "        li = a[i+1:,i]/a[i,i]\n",
    "        b[i+1:] = b[i+1:] - li * b[i]\n",
    "        a[i+1:] = a[i+1:] - li.reshape(n-i-1,1)*a[i]\n",
    "        \n",
    "def gaussian_elimination_with_total_pivoting(a, b): \n",
    "\n",
    "    n = b.size\n",
    "    ord_col = np.arange(n)\n",
    "    for i in range(n-1):\n",
    "        # total pivoting\n",
    "        i_max, j_max = np.unravel_index(np.abs(a[i:,i:]).argmax(), a[i:,i:].shape)\n",
    "        a[[i,i_max+i]] = a[[i_max+i,i]]\n",
    "        a[:,[i,j_max+i]] = a[:,[j_max+i,i]]\n",
    "        b[[i,i_max+i]] = b[[i_max+i,i]]\n",
    "        ord_col[[i,j_max+i]] = ord_col[[j_max+i,i]]\n",
    "        # elimination\n",
    "        li = a[i+1:,i]/a[i,i]\n",
    "        b[i+1:] = b[i+1:] - li * b[i]\n",
    "        a[i+1:] = a[i+1:] - li.reshape(n-i-1,1)*a[i]\n",
    "        \n",
    "    return ord_col\n",
    "\n",
    "def backward_substitution(a, b):\n",
    "    n = b.size\n",
    "    x = np.empty(n)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        x[i] = (b[i] - np.sum(a[i,i+1:]*x[i+1:])) / a[i,i]\n",
    "    return x\n",
    "\n",
    "def gauss_solve_without_pivoting(a, b):\n",
    "    ag = np.copy(a) \n",
    "    bg = np.copy(b)\n",
    "    gaussian_elimination_without_pivoting(ag, bg)\n",
    "    return backward_substitution(ag, bg)\n",
    "\n",
    "def gauss_solve_with_partial_pivoting(a, b):\n",
    "    ag = np.copy(a) \n",
    "    bg = np.copy(b)\n",
    "    gaussian_elimination_with_partial_pivoting(ag, bg)\n",
    "    return backward_substitution(ag, bg)\n",
    "\n",
    "\n",
    "def gauss_solve_with_total_pivoting(a, b):\n",
    "    ag = np.copy(a) \n",
    "    bg = np.copy(b)\n",
    "    ord_col = gaussian_elimination_with_total_pivoting(ag, bg)\n",
    "    x = backward_substitution(ag, bg)\n",
    "    return x[ord_col.argsort()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices aléatoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque taille n = 5,6,...,55 nous choisissons 80 matrices aléatoires avec coefficients $a_{ij}$ uniformément distribués dans $[−1, 1]$ et des solutions $x_i$ uniformément distribuées dans $[−1, 1]$ en double précision. Nous calculons alors en quadruple précision les $b_j$ pour cette solution exacte. Ensuite nous appliquons l’algorithme de Gauss, une fois sans recherche de pivot, puis avec recherche de pivot partielle et avec recherche de pivot totale, en double précision. \n",
    "\n",
    "Le fait d'avoir accès à la solution exacte et à une solution en double précision pour les divers algorithmes permet une évaluation de l'erreur générée par l'utilisation de l'algorithme en double précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gauss_without_pivoting(n_test):\n",
    "\n",
    "    err = np.zeros((51,n_test))\n",
    "    errovercond = np.zeros((51,n_test))\n",
    "\n",
    "    print(\"\\nGauss without pivoting\")\n",
    "\n",
    "    for i, i_n in enumerate(range(5,56)):\n",
    "        for j in range(n_test):\n",
    "            a = mp.mpf('2.0')*np.random.random((i_n,i_n))-1\n",
    "            # à décommenter pour voir l'impact du pivot total\n",
    "            # a[1,i_n-1] = mp.mpf('100000')\n",
    "            x_ex = mp.mpf('2.0')*np.random.random(i_n)-1\n",
    "            b = np.dot(a, x_ex)\n",
    "            a_64 = a.astype(np.float64)\n",
    "            b_64 = b.astype(np.float64)\n",
    "            x_num = gauss_solve_without_pivoting(a_64, b_64)\n",
    "            err[i,j] = np.linalg.norm(np.abs(x_num-x_ex), np.inf)\n",
    "            errovercond[i,j] = err[i,j] / np.linalg.cond(a_64, np.inf)\n",
    "            \n",
    "    return err, errovercond\n",
    "\n",
    "def test_gauss_with_partial_pivoting(n_test):\n",
    "\n",
    "    err = np.zeros((51,n_test))\n",
    "    errovercond = np.zeros((51,n_test))\n",
    "        \n",
    "    print(\"\\nGauss with partial pivoting\")\n",
    " \n",
    "    for i, i_n in enumerate(range(5,56)):\n",
    "        #print(\".\", end=\"\")\n",
    "        for j in range(n_test):\n",
    "            a = mp.mpf('2.0')*np.random.random((i_n,i_n))-1\n",
    "            # à décommenter pour voir l'impact du pivot total\n",
    "            # a[1,i_n-1] = mp.mpf('100000')\n",
    "            x_ex = mp.mpf('2.0')*np.random.random(i_n)-1\n",
    "            b = np.dot(a, x_ex)\n",
    "            a_64 = a.astype(np.float64)\n",
    "            b_64 = b.astype(np.float64)\n",
    "            x_num = gauss_solve_with_partial_pivoting(a_64, b_64)\n",
    "            err[i,j] = np.linalg.norm(np.abs(x_num-x_ex), np.inf)\n",
    "            errovercond[i,j] = err[i,j] / np.linalg.cond(a_64, np.inf)\n",
    "            \n",
    "    return err, errovercond\n",
    "\n",
    "def test_gauss_with_total_pivoting(n_test):\n",
    "\n",
    "    err = np.zeros((51,n_test))\n",
    "    errovercond = np.zeros((51,n_test))\n",
    "        \n",
    "    print(\"\\nGauss with total pivoting\")\n",
    " \n",
    "    for i, i_n in enumerate(range(5,56)):\n",
    "        for j in range(n_test):\n",
    "            a = mp.mpf('2.0')*np.random.random((i_n,i_n))-1\n",
    "            # à décommenter pour voir l'impact du pivot total\n",
    "            # a[1,i_n-1] = mp.mpf('100000')\n",
    "            x_ex = mp.mpf('2.0')*np.random.random(i_n)-1\n",
    "            b = np.dot(a, x_ex)\n",
    "            a_64 = a.astype(np.float64)\n",
    "            b_64 = b.astype(np.float64)\n",
    "            x_num = gauss_solve_with_total_pivoting(a_64, b_64)\n",
    "            err[i,j] = np.linalg.norm(np.abs(x_num-x_ex), np.inf)\n",
    "            errovercond[i,j] = err[i,j] / np.linalg.cond(a_64, np.inf)\n",
    "            \n",
    "    return err, errovercond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb de matrices testées par taille\n",
    "n_test = 80\n",
    "\n",
    "err_1, errovercond_1 = test_gauss_without_pivoting(n_test)\n",
    "err_2, errovercond_2 = test_gauss_with_partial_pivoting(n_test)\n",
    "err_3, errovercond_3 = test_gauss_with_total_pivoting(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La norme infinie de l'erreur $(x_i^{num} − x_i^{ex})$ puis la norme infinie de l'erreur divisée par le conditionnement de chaque résultat est représentée sur la figure suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=3, vertical_spacing=0.1, subplot_titles=(\"|err|_inf\", \"|err|_inf\", \"|err|_inf\", \"|err|_inf/cond\", \"|err|_inf/cond\", \"|err|_inf/cond>\"))\n",
    "\n",
    "for i, i_n in enumerate(range(5,56)):\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=err_1[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=err_2[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=err_3[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=1, col=3)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=errovercond_1[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=errovercond_2[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=errovercond_3[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=2, col=3)\n",
    "\n",
    "fig.update_yaxes(type=\"log\", range=[-17,-8],  exponentformat = 'e', row=1)    \n",
    "fig.update_yaxes(type=\"log\", range=[-19,-11], exponentformat = 'e', row=2)    \n",
    "    \n",
    "fig.update_layout(height=1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas sans recherche de pivot, le niveau général d'erreur est bien supérieur à celui du cas avec recherche de pivot. Le conditionnement est le même dans les deux cas, celui de\n",
    "la matrice $A$.\n",
    "\n",
    "Afin de préciser l'origine des erreurs, nous avons représenté l'erreur précédente divisée par le conditionnement de la matrice. Il apparaît clairement que ce nombre reste en dessous de la précision machine en double précision dans le cas où l'on emploie une technique de pivotage. Cela indique un algorithme très stable au sens backward. Ce n'est pas la cas de l'algorithme sans pivot qui peut poser de sérieux problèmes de précision. Le choix du pivotage partiel mène à une algorithme qui se comporte bien dans la plupart des cas mais à une coût moindre par rapport au pivot total que l'on utile plus rarement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices orthogonales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette deuxième expérience numérique, nous tirons 80 matrices aléatoires $a_{ij}$ orthogonale . Cette matrice est calculée en double précision, le reste de l’expérience continue comme auparavant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ortho_gauss_without_pivoting(n_test):\n",
    "\n",
    "    err = np.zeros((51,n_test))\n",
    "    errovercond = np.zeros((51,n_test))\n",
    "\n",
    "    print(\"\\nGauss without pivoting\")\n",
    "\n",
    "    for i, i_n in enumerate(range(5,56)):\n",
    "        for j in range(n_test):\n",
    "            a = mp.mpf('1.0')*ortho_group.rvs(dim=i_n)\n",
    "            x_ex = mp.mpf('2.0')*np.random.random(i_n)-1\n",
    "            b = np.dot(a, x_ex)\n",
    "            a_64 = a.astype(np.float64)\n",
    "            b_64 = b.astype(np.float64)\n",
    "            x_num = gauss_solve_without_pivoting(a_64, b_64)\n",
    "            err[i,j] = np.linalg.norm(np.abs(x_num-x_ex), np.inf)\n",
    "            errovercond[i,j] = err[i,j] / np.linalg.cond(a_64, np.inf)\n",
    "            \n",
    "    return err, errovercond\n",
    "\n",
    "def test_ortho_gauss_with_partial_pivoting(n_test):\n",
    "\n",
    "    err = np.zeros((51,n_test))\n",
    "    errovercond = np.zeros((51,n_test))\n",
    "        \n",
    "    print(\"\\nGauss with partial pivoting\")\n",
    " \n",
    "    for i, i_n in enumerate(range(5,56)):\n",
    "        for j in range(n_test):\n",
    "            a = mp.mpf('1.0')*ortho_group.rvs(dim=i_n)\n",
    "            x_ex = 2*np.random.random(i_n)-1\n",
    "            b = np.dot(a, x_ex)\n",
    "            a_64 = a.astype(np.float64)\n",
    "            b_64 = b.astype(np.float64)\n",
    "            x_num = gauss_solve_with_partial_pivoting(a_64, b_64)\n",
    "            err[i,j] = np.linalg.norm(np.abs(x_num-x_ex), np.inf)\n",
    "            errovercond[i,j] = err[i,j] / np.linalg.cond(a_64, np.inf)\n",
    "            \n",
    "    return err, errovercond\n",
    "\n",
    "def test_ortho_gauss_with_total_pivoting(n_test):\n",
    "\n",
    "    err = np.zeros((51,n_test))\n",
    "    errovercond = np.zeros((51,n_test))\n",
    "        \n",
    "    print(\"\\nGauss with total pivoting\")\n",
    " \n",
    "    for i, i_n in enumerate(range(5,56)):\n",
    "        for j in range(n_test):\n",
    "            a = mp.mpf('1.0')*ortho_group.rvs(dim=i_n)\n",
    "            x_ex = 2*np.random.random(i_n)-1\n",
    "            b = np.dot(a, x_ex)\n",
    "            a_64 = a.astype(np.float64)\n",
    "            b_64 = b.astype(np.float64)\n",
    "            x_num = gauss_solve_with_total_pivoting(a_64, b_64)\n",
    "            err[i,j] = np.linalg.norm(np.abs(x_num-x_ex), np.inf)\n",
    "            errovercond[i,j] = err[i,j] / np.linalg.cond(a_64, np.inf)\n",
    "            \n",
    "    return err, errovercond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb de matrices testées par taille\n",
    "n_test = 80\n",
    "\n",
    "err_4, errovercond_4 = test_ortho_gauss_without_pivoting(n_test)\n",
    "err_5, errovercond_5 = test_ortho_gauss_with_partial_pivoting(n_test)\n",
    "err_6, errovercond_6 = test_ortho_gauss_with_total_pivoting(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La norme infinie de l'erreur $(x_i^{num} − x_i^{ex})$ puis la norme infinie de l'erreur divisée par le conditionnement de chaque résultat est représentée sur la figure suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=3, vertical_spacing=0.1, subplot_titles=(\"|err|_inf\", \"|err|_inf\", \"|err|_inf\", \"|err|_inf/cond\", \"|err|_inf/cond\", \"|err|_inf/cond>\"))\n",
    "\n",
    "for i, i_n in enumerate(range(5,56)):\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=err_4[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=err_5[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=err_6[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=1, col=3)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=errovercond_4[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=errovercond_5[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(x=np.ones(n_test)*i_n, y=errovercond_6[i], showlegend=False, mode=\"markers\", marker_color='blue', marker_size=3), row=2, col=3)\n",
    "\n",
    "fig.update_yaxes(type=\"log\", range=[-17,-8],  exponentformat = 'e', row=1)    \n",
    "fig.update_yaxes(type=\"log\", range=[-18,-10], exponentformat = 'e', row=2)    \n",
    "    \n",
    "fig.update_layout(height=1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons que lorsque nous utilisons la recherche de pivot partielle,  il n'y a pas d'exception dans la bonne performance de l'algorithme de Gauss puisqu'on ne peut pas avoir de matrice mal-conditionnée dans ce cas! \n",
    "\n",
    "Par ailleurs, les conclusions sont les mêmes en ce qui concerne la stabilité des algorithmes, à ceci près que les erreurs ici sont uniquement générées par la perte potentielle de stabilité des algorithmes, puisque toutes les matrices sont bien conditionnées. \n",
    "\n",
    "Remarquons que ce sont les erreurs en norme infinie qui sont présentées et que l'on observe une croissance légère avec la dimension des matrices, ce qui ne serait pas le cas en norme 2.\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
