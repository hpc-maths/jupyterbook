# V - Résolution des systèmes linéaires par des méthodes itératives

Les méthodes directes souffrent d'une capacité limitée de parallélisation et l'utilisation d'un algorithme direct avec pivot peut coûter cher en temps de calcul lorsque la taille de la matrice devient trop grande et en particulier lorsque l'on s'oriente vers des problèmes résultant de la discrétisation d'EDP en dimension 3. Lorsque la taille de la matrice augmente, les matrices sont bien creuses mais le stockage associé à la décomposition LU devient très élevé alors que le conditionnement n'est pas forcément très grand.

Des méthodes itératives existent depuis longtemps introduites par Jacobi et Gauss (ainsi que Ludwig von Seidel) mais certaines peuvent converger lentement. Les méthodes itératives sont revenues au goût du jour pour pouvoir attaquer des problèmes de grande taille et en particulier dans le cadre du calcul haute performance pour des matrices creuses et les problèmes réalistes actuels. Par contre, nous disposons de moins de résultats théoriques que pour les méthodes directes et l’expérimentation numérique est ici importante. 

Dans ce chapitre, nous commençons par une mise en œuvre des méthodes stationnaires de Jacobi et Gauss-Seidel sur le cas classique de l’équation de Poisson avec terme source et conditions aux limites de Dirichlet. L’historique de convergence est mis en perspective de celui obtenu par une méthode de gradient conjugué afin d'analyser l'efficacité de la méthode nonstationnaire.

Dans un second notebook, l’intérêt de l’approche de type gradient conjugué par rapport à une méthode de gradient classique, voir optimisé, est démontré dans un cas très simple d’une matrice 2x2 avec illustration graphique de l’historique de « descente ». 

Il nous a paru essentiel de bien illustrer le fait que la résolution de l’équation de Poisson en 1D, 2D ou 3D, avec un nombre total de degrés de liberté fixé, demande des algorithmes différents pour être efficace. Ce cas nous a été soufflé par Y. Saad ! Nous prenons N=122550 degrés de liberté, ce qui correspond à un cas 2D 350x350 ou un cas 3D 50x50x49. En choisissant d’une part l’approche du gradient conjugué comme méthode itérative, et d’autre par l’élimination de Gauss avec pivot partiel, nous pouvons conclure sur le fait que les approches directes sont efficaces dans le cas 1D et 2D mais deviennent très lourdes en 3D (largeur de bande / coût du pivotage), alors que l’approche itérative est particulièrement intéressante dans ce cas 3D (mais ttès mauvaise dans le cas 1D du fait du conditionnement). En effet, le conditionnement est relativement sympathique dans le cas 3D et conduit à une convergence rapide. Le constat observé sur ce cas simple a une portée relativement générale.

Pour terminer, comme dans la pratique il s’agit d’utiliser un préconditionneur pour mener à une convergence améliorée, nous avons mis en œuvre le préconditionnement polynomial (qui se prête bien à une parallélisation) de type Tchebyshef pour le gradient conjugué. Force est de constater son impact sur la convergence lors de la résolution du problème de Poisson en 1D, 2D et surtout 3D, cas le plus intéressant pour les méthodes itératives.

